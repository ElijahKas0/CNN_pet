## Смысл трехслойной нейронной сети
- Когда мы двухслойную нейронную сеть превращаем в однослойную мы не получаем никаких преимуществ, т.к. всё, что может сделать двухслойная нейронная сеть может и однослойная (Пример из Грокаем глубокое обучение: 1*0.25*0.9(слой трёхслойной)=1*0.225(слой двухслойной)=0.225)
- То есть в трёхслойной нейронной сети мы просто изменяем комбинации входных данных, не добавляя никакой информации для выходного слоя.
- Для того, чтобы мы могли трёхслойную сеть использовать эффективнее, нам необходимо помочь сети определять, какие узлы коррелируют (толкают сеть к значимому для нас ответу - когда переходить дорогу например, т.к. стоять на светофоре я могу и без помощи нейросети) с выходным слоем. 
- Для этого незначимые узлы (которые говорят например, вот при такой комбинации огней светофора точно нужно стоять), мы зануляем. Мы это делаем т.к. незначимые узлы чаще всего принимают значения ниже нуля. А это может сместить ошибку в их сторону. То есть ошибка (разница между предсказанием и реальными данными, на основе которой идёт обучение) может стать очень низкой или стать вообще другого знака(по сравнению со значащим, коррелирующим узлом), а это значит, что коррелирующий узел может медленно обучаться, либо обучаться вообще не в ту сторону (из-за знака).
- Это зануление осуществляется с помощью функции ReLU (max(0,x))
- И это всё только в контексте положительных входных и выходных данных. Когда данные положительны и мы хотим узнать, при каких условиях возникает положительный результат, мы хотим выделить узлы, которые коррелируют с выходным слоем, а они чаще всего будут положительными (они как бы говорят: с большей или меньше степенью тебе надо переходить дорогу при моём значении, а моё значение - это определённое сочетание сигналов светофора, то есть некий шаблон, при которой тебе можно с большей или меньше вероятность перейти дорогу)
- В итоге в процессе обучения выделяются шаблоны, которые значимы, а на их основе выделяются входные данные(конкретные огни светофора - загорелся правый, загорелся левый, загорелся посередине). А выделятся они присвоением им большого веса в процессе обучения
- Но почему в таком случае не возникает больше ложноположительных предсказаний нейросети ? (Мы ведь зануляем те шаблоны, которые говорят нам, что надо стоять, например). Ответ заключается в обучении. Если положительный шаблон в процессе обучения правильно объяснял несколько выходных данных подряд, а потом перестал, то градиентный спуск сильно обвалит значения веса этого шаблона, а за ним и значения весов входных данных, составляющих этот шаблон из-за большой ошибки, которая появится при неправильном предсказании выходного значения этим шаблоном 
- Ну и последнее, обратное распространение градиента не нужно для нулевого узла, ведь его незачем обучать - он незначим
